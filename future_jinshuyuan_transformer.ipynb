{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:38:52.146424: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19136/19136 [==============================] - 2279s 119ms/step - loss: 0.6222\n",
      "Epoch 2/5\n",
      " 7897/19136 [===========>..................] - ETA: 19:18 - loss: 0.6174"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zhangwenbo/testProjects/laplace/future_jinshuyuan_transformer.ipynb 单元格 1\u001b[0m line \u001b[0;36m<cell line: 141>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zhangwenbo/testProjects/laplace/future_jinshuyuan_transformer.ipynb#W0sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zhangwenbo/testProjects/laplace/future_jinshuyuan_transformer.ipynb#W0sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39m# 使用生成器训练模型\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/zhangwenbo/testProjects/laplace/future_jinshuyuan_transformer.ipynb#W0sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zhangwenbo/testProjects/laplace/future_jinshuyuan_transformer.ipynb#W0sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/zhangwenbo/testProjects/laplace/future_jinshuyuan_transformer.ipynb#W0sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodel_transformer.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout,GlobalAveragePooling1D,LayerNormalization, MultiHeadAttention\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "data_clean = pd.read_csv(\"future_ss2312_tick.csv\")\n",
    "\n",
    "# 1. 数据加载和预处理\n",
    "# 确保'close'列是数值型\n",
    "data_clean['close'] = pd.to_numeric(data_clean['close'], errors='coerce')\n",
    "\n",
    "price_features = ['昨收盘', '今开盘', '最高价', '最低价', '申买价一', '申卖价一']\n",
    "for feature in price_features:\n",
    "    data_clean[feature + '_diff'] = data_clean['close'] - data_clean[feature]\n",
    "\n",
    "data_clean['trade_time'] = pd.to_datetime(data_clean['trade_time'])\n",
    "\n",
    "# 将时间分解为小时和分钟\n",
    "data_clean['hour'] = data_clean['trade_time'].dt.hour\n",
    "data_clean['minute'] = data_clean['trade_time'].dt.minute\n",
    "\n",
    "data_clean['close_diff'] = data_clean['close'].diff()\n",
    "\n",
    "# Define label\n",
    "data_clean['label'] = (data_clean['close'].shift(-100) > data_clean['close']).astype(int)\n",
    "\n",
    "features = ['close_diff', '数量', 'hour', 'minute'] + [f + '_diff' for f in price_features]\n",
    "\n",
    "# 3. 分割数据\n",
    "\n",
    "# Now you can filter the data between two dates\n",
    "train_data = data_clean[(data_clean['trade_time'] >= '2023-09-01 09:00:00') & \n",
    "                        (data_clean['trade_time'] < '2023-10-12 09:00:00')]\n",
    "\n",
    "test_data = data_clean[(data_clean['trade_time'] >= '2023-10-12 09:00:00') & \n",
    "                        (data_clean['trade_time'] < '2023-10-20 09:00:00')]\n",
    "\n",
    "\n",
    "# 初始化归一化器\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_data[features] = scaler.fit_transform(train_data[features])\n",
    "\n",
    "\n",
    "# 将 DataFrame 转换为 NumPy 数组\n",
    "X_train = np.array(train_data[features])\n",
    "y_train = np.array(train_data['label'])\n",
    "\n",
    "# 删除 NaN 值\n",
    "mask = ~np.isnan(X_train).any(axis=1)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "# 首先，确保 X_train 和 X_test 没有 NaN 值\n",
    "X_train = X_train[~np.isnan(X_train).any(axis=1)]\n",
    "y_train = y_train[~np.isnan(X_train).any(axis=1)]\n",
    "\n",
    "# Transformer Block\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TimeseriesGenerator(Sequence):\n",
    "    def __init__(self, data, labels, length, stride=1, batch_size=32):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.length = length\n",
    "        self.stride = stride\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil((len(self.data) - self.length) / float(self.stride * self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "\n",
    "        start = idx * self.batch_size * self.stride\n",
    "        end = start + self.batch_size * self.stride + self.length\n",
    "\n",
    "        for i in range(start, min(end, len(self.data) - self.length), self.stride):\n",
    "            batch_x.append(self.data[i: i + self.length])\n",
    "            batch_y.append(self.labels[i + self.length])\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "\n",
    "# 定义时间步长\n",
    "time_steps = 200  # 例如，选择200作为时间步长\n",
    "stride = 1\n",
    "\n",
    "# 创建数据生成器\n",
    "train_generator = TimeseriesGenerator(X_train, y_train, length=time_steps, stride=stride, batch_size=32)\n",
    "\n",
    "# 确定输入特征的维度\n",
    "input_feature_dim = X_train.shape[1]\n",
    "\n",
    "# 定义模型\n",
    "embed_dim = input_feature_dim  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(time_steps, input_feature_dim)))  # 明确指定输入形状\n",
    "model.add(TransformerBlock(embed_dim, num_heads, ff_dim))\n",
    "model.add(GlobalAveragePooling1D())  # 添加池化层以压缩时间维度\n",
    "model.add(Dense(1, activation='sigmoid'))  # 输出层\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "# 使用生成器训练模型\n",
    "model.fit(train_generator, epochs=5)\n",
    "\n",
    "from keras.models import load_model\n",
    "model.save('model_transformer.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8407203\n",
      "Time: 2023-10-17 09:05:39 - Action: BUY at 14805.0, Quantity: 6.0,Funds:11158.0\n",
      "-14.871629\n",
      "Time: 2023-10-17 09:07:56 - Action: SELL at 14830.0, Quantity: 6.0,Funds:100138.0, Price Change: 涨\n",
      "0.65836716\n",
      "Time: 2023-10-17 09:09:30 - Action: BUY at 14820.0, Quantity: 6.0,Funds:11206.0\n",
      "-18.44158\n",
      "Time: 2023-10-17 09:11:46 - Action: SELL at 14840.0, Quantity: 6.0,Funds:100246.0, Price Change: 涨\n",
      "0.61604077\n",
      "Time: 2023-10-17 09:15:19 - Action: BUY at 14820.0, Quantity: 6.0,Funds:11314.0\n",
      "-11.009768\n",
      "Time: 2023-10-17 09:18:59 - Action: SELL at 14825.0, Quantity: 6.0,Funds:100264.0, Price Change: 涨\n",
      "0.73307836\n",
      "Time: 2023-10-17 09:59:17 - Action: BUY at 14815.0, Quantity: 6.0,Funds:11362.0\n",
      "-12.988117\n",
      "Time: 2023-10-17 10:02:46 - Action: SELL at 14815.0, Quantity: 6.0,Funds:100252.0, Price Change: 平\n",
      "2.3447926\n",
      "Time: 2023-10-17 10:30:37 - Action: BUY at 14810.0, Quantity: 6.0,Funds:11380.0\n",
      "-10.111759\n",
      "Time: 2023-10-17 10:33:49 - Action: SELL at 14800.0, Quantity: 6.0,Funds:100180.0, Price Change: 跌\n",
      "3.784213\n",
      "Time: 2023-10-17 10:35:02 - Action: BUY at 14795.0, Quantity: 6.0,Funds:11398.0\n",
      "-13.271388\n",
      "Time: 2023-10-17 10:39:06 - Action: SELL at 14810.0, Quantity: 6.0,Funds:100258.0, Price Change: 涨\n",
      "1.1311582\n",
      "Time: 2023-10-17 10:41:05 - Action: BUY at 14795.0, Quantity: 6.0,Funds:11476.0\n",
      "-10.057552\n",
      "Time: 2023-10-17 10:45:07 - Action: SELL at 14785.0, Quantity: 6.0,Funds:100186.0, Price Change: 跌\n",
      "0.7091444\n",
      "Time: 2023-10-17 10:50:14 - Action: BUY at 14765.0, Quantity: 6.0,Funds:11584.0\n",
      "-0.86007094\n",
      "Time: 2023-10-17 10:52:41 - Action: SELL at 14770.0, Quantity: 6.0,Funds:100204.0, Price Change: 涨\n",
      "0.8834555\n",
      "Time: 2023-10-17 10:56:25 - Action: BUY at 14765.0, Quantity: 6.0,Funds:11602.0\n",
      "-4.2647886\n",
      "Time: 2023-10-17 11:00:01 - Action: SELL at 14765.0, Quantity: 6.0,Funds:100192.0, Price Change: 平\n",
      "1.4933289\n",
      "Time: 2023-10-17 11:16:09 - Action: BUY at 14775.0, Quantity: 6.0,Funds:11530.0\n",
      "-3.0063674\n",
      "Time: 2023-10-17 11:18:49 - Action: SELL at 14775.0, Quantity: 6.0,Funds:100180.0, Price Change: 平\n",
      "2.6386125\n",
      "Time: 2023-10-17 13:38:11 - Action: BUY at 14790.0, Quantity: 6.0,Funds:11428.0\n",
      "-2.663479\n",
      "Time: 2023-10-17 13:44:59 - Action: SELL at 14785.0, Quantity: 6.0,Funds:100138.0, Price Change: 跌\n",
      "1.1531065\n",
      "Time: 2023-10-17 13:49:12 - Action: BUY at 14800.0, Quantity: 6.0,Funds:11326.0\n",
      "-9.535201\n",
      "Time: 2023-10-17 13:52:41 - Action: SELL at 14810.0, Quantity: 6.0,Funds:100186.0, Price Change: 涨\n",
      "2.0080485\n",
      "Time: 2023-10-17 14:03:33 - Action: BUY at 14790.0, Quantity: 6.0,Funds:11434.0\n",
      "-10.833034\n",
      "Time: 2023-10-17 14:08:29 - Action: SELL at 14800.0, Quantity: 6.0,Funds:100234.0, Price Change: 涨\n",
      "2.94539\n",
      "Time: 2023-10-17 14:38:11 - Action: BUY at 14775.0, Quantity: 6.0,Funds:11572.0\n",
      "-2.4474368\n",
      "Time: 2023-10-17 14:42:36 - Action: SELL at 14775.0, Quantity: 6.0,Funds:100222.0, Price Change: 平\n",
      "1.58919\n",
      "Time: 2023-10-17 14:45:01 - Action: BUY at 14770.0, Quantity: 6.0,Funds:11590.0\n",
      "-0.24471952\n",
      "Time: 2023-10-17 14:48:17 - Action: SELL at 14765.0, Quantity: 6.0,Funds:100180.0, Price Change: 跌\n",
      "1.344682\n",
      "Time: 2023-10-17 14:48:54 - Action: BUY at 14760.0, Quantity: 6.0,Funds:11608.0\n",
      "-2.4787161\n",
      "Time: 2023-10-17 14:51:49 - Action: SELL at 14760.0, Quantity: 6.0,Funds:100168.0, Price Change: 平\n",
      "1.4711816\n",
      "Time: 2023-10-17 14:52:05 - Action: BUY at 14760.0, Quantity: 6.0,Funds:11596.0\n",
      "-1.8281659\n",
      "Time: 2023-10-17 14:54:18 - Action: SELL at 14760.0, Quantity: 6.0,Funds:100156.0, Price Change: 平\n",
      "2.2409127\n",
      "Time: 2023-10-17 14:54:18 - Action: BUY at 14760.0, Quantity: 6.0,Funds:11584.0\n",
      "-0.35740763\n",
      "Time: 2023-10-17 14:56:42 - Action: SELL at 14765.0, Quantity: 6.0,Funds:100174.0, Price Change: 涨\n",
      "1.7291745\n",
      "Time: 2023-10-17 14:57:06 - Action: BUY at 14760.0, Quantity: 6.0,Funds:11602.0\n",
      "-14.1900835\n",
      "Time: 2023-10-17 14:59:45 - Action: SELL at 14775.0, Quantity: 6.0,Funds:100252.0, Price Change: 涨\n",
      "1.1832201\n",
      "Time: 2023-10-17 14:59:47 - Action: BUY at 14765.0, Quantity: 6.0,Funds:11650.0\n",
      "-14.002709\n",
      "Time: 2023-10-17 21:01:30 - Action: SELL at 14925.0, Quantity: 6.0,Funds:101200.0, Price Change: 涨\n",
      "3.1925578\n",
      "Time: 2023-10-18 14:44:43 - Action: BUY at 14685.0, Quantity: 6.0,Funds:13078.0\n",
      "-9.759301\n",
      "Time: 2023-10-18 14:46:24 - Action: SELL at 14705.0, Quantity: 6.0,Funds:101308.0, Price Change: 涨\n",
      "0.8949732\n",
      "Time: 2023-10-19 09:04:01 - Action: BUY at 14665.0, Quantity: 6.0,Funds:13306.0\n",
      "-13.786307\n",
      "Time: 2023-10-19 09:05:54 - Action: SELL at 14675.0, Quantity: 6.0,Funds:101356.0, Price Change: 涨\n",
      "涨    12\n",
      "平     6\n",
      "跌     4\n",
      "Name: price_change, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "# 假设这些变量已经在上下文中定义\n",
    "# model = load_model('gru_model.h5')\n",
    "time_steps = 200\n",
    "price_features = ['昨收盘', '今开盘', '最高价', '最低价', '申买价一', '申卖价一']\n",
    "features = ['close_diff', '数量', 'hour', 'minute'] + [f + '_diff' for f in price_features]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "def prepare_data_for_prediction(test_data, time_steps, scaler):\n",
    "\n",
    "    # 使用归一化\n",
    "    scaled_data = scaler.fit_transform(test_data[features].dropna())\n",
    "\n",
    "    # 重塑数据以适应模型\n",
    "    X = np.array([scaled_data[i:i+time_steps] for i in range(len(scaled_data)-time_steps+1)])\n",
    "    return X\n",
    "\n",
    "# 准备数据\n",
    "X_test = prepare_data_for_prediction(test_data, time_steps, scaler)\n",
    "# 批量预测\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "# 确保test_data的索引与predictions对齐\n",
    "aligned_test_data = test_data.iloc[time_steps - 1:]\n",
    "\n",
    "\n",
    "initial_funds = 100000\n",
    "funds = initial_funds\n",
    "stock_quantity = 0\n",
    "stock_price = 0\n",
    "buy_threshold = 0.6\n",
    "sold_threshold = 0.4\n",
    "transactions = []\n",
    "minute_count = 0\n",
    "for prediction,  (index, row)  in zip(predictions, aligned_test_data.iterrows()):\n",
    "    current_probability = prediction[0]\n",
    "    if current_probability is not None:\n",
    "        current_price = row['close']\n",
    "        minute_count = minute_count + 1\n",
    "            \n",
    "        if current_probability > buy_threshold and stock_quantity == 0 :\n",
    "            print(current_probability)\n",
    "            stock_quantity = funds // current_price\n",
    "            funds -= stock_quantity * current_price\n",
    "            fee = stock_quantity * 2\n",
    "            funds -= fee\n",
    "            stock_price = current_price\n",
    "            buy_price = current_price  # 记录买入价格\n",
    "            print(f\"Time: {row['trade_time']} - Action: BUY at {current_price}, Quantity: {stock_quantity},Funds:{funds}\")\n",
    "            transactions.append({\n",
    "                'action': 'buy',\n",
    "                'time': row['trade_time'],\n",
    "                'price': current_price,\n",
    "                'quantity': stock_quantity,\n",
    "                'funds_remaining': funds\n",
    "            })\n",
    "            minute_count = 0\n",
    "        elif minute_count > 200 and stock_quantity > 0 and current_probability<sold_threshold:\n",
    "            print(current_probability)\n",
    "            funds += stock_quantity * current_price\n",
    "            price_diff = current_price - buy_price  # 计算价格差异\n",
    "            # 判断价格差异是涨、跌还是平\n",
    "            if price_diff > 0:\n",
    "                direction = '涨'\n",
    "            elif price_diff < 0:\n",
    "                direction = '跌'\n",
    "            else:\n",
    "                direction = '平'\n",
    "            print(f\"Time: {row['trade_time']} - Action: SELL at {current_price}, Quantity: {stock_quantity},Funds:{funds}, Price Change: {direction}\")\n",
    "            transactions.append({\n",
    "                'action': 'sell',\n",
    "                'time': row['trade_time'],\n",
    "                'price': current_price,\n",
    "                'quantity': stock_quantity,\n",
    "                'funds_remaining': funds,\n",
    "                'price_change': direction\n",
    "            })\n",
    "            stock_quantity = 0\n",
    "            buy_price = 0  # 重置买入价格为0\n",
    "\n",
    "    \n",
    "if len(transactions)>0:\n",
    "    transactions_df = pd.DataFrame(transactions)\n",
    "    print(transactions_df['price_change'].value_counts())\n",
    "transactions_df.to_csv('transactions_tick_transformer.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
