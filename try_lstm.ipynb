{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 15:08:36.876448: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 7ms/step - loss: 0.3493\n",
      "Epoch 2/60\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6213\n",
      "Epoch 3/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2011\n",
      "Epoch 4/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.3613\n",
      "Epoch 5/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5176\n",
      "Epoch 6/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1616\n",
      "Epoch 7/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1114\n",
      "Epoch 8/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1360\n",
      "Epoch 9/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2452\n",
      "Epoch 10/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1139\n",
      "Epoch 11/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6162\n",
      "Epoch 12/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3896\n",
      "Epoch 13/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2165\n",
      "Epoch 14/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0984\n",
      "Epoch 15/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4967\n",
      "Epoch 16/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1170\n",
      "Epoch 17/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1599\n",
      "Epoch 18/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1112\n",
      "Epoch 19/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5187\n",
      "Epoch 20/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5338\n",
      "Epoch 21/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5156\n",
      "Epoch 22/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1305\n",
      "Epoch 23/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1646\n",
      "Epoch 24/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2967\n",
      "Epoch 25/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4320\n",
      "Epoch 26/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2024\n",
      "Epoch 27/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2480\n",
      "Epoch 28/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3069\n",
      "Epoch 29/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1148\n",
      "Epoch 30/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1290\n",
      "Epoch 31/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3569\n",
      "Epoch 32/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1949\n",
      "Epoch 33/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.8944\n",
      "Epoch 34/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4446\n",
      "Epoch 35/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1503\n",
      "Epoch 36/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1011\n",
      "Epoch 37/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1273\n",
      "Epoch 38/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1665\n",
      "Epoch 39/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1580\n",
      "Epoch 40/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3296\n",
      "Epoch 41/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3457\n",
      "Epoch 42/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1962\n",
      "Epoch 43/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0837\n",
      "Epoch 44/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4252\n",
      "Epoch 45/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1036\n",
      "Epoch 46/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1385\n",
      "Epoch 47/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0976\n",
      "Epoch 48/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4530\n",
      "Epoch 49/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4655\n",
      "Epoch 50/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4623\n",
      "Epoch 51/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1208\n",
      "Epoch 52/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1682\n",
      "Epoch 53/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2674\n",
      "Epoch 54/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4282\n",
      "Epoch 55/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1847\n",
      "Epoch 56/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2379\n",
      "Epoch 57/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2755\n",
      "Epoch 58/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1135\n",
      "Epoch 59/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1212\n",
      "Epoch 60/60\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3287\n",
      "1/1 [==============================] - 0s 171ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangwenbo/miniforge3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv('stock_data.csv')  # 确保文件路径是正确的\n",
    "data.sort_index(ascending=False, inplace=True)\n",
    "data = data.reset_index(drop=True)\n",
    "data.columns = ['price', 'vol']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "train_data = data_scaled\n",
    "\n",
    "def generator(data, lookback=10, delay=1, batch_size=32):\n",
    "    max_index = len(data) - delay - 1\n",
    "    i = lookback\n",
    "    while 1:\n",
    "        if i + delay >= max_index:\n",
    "            i = lookback\n",
    "        samples = np.zeros((batch_size, lookback, data.shape[-1]))\n",
    "        targets = np.zeros((batch_size, data.shape[-1]))  # 生成器的目标现在包括所有特征\n",
    "        for j in range(batch_size):\n",
    "            if i + delay >= max_index:\n",
    "                i = lookback\n",
    "            rows = np.arange(i - lookback, i)\n",
    "            samples[j] = data[rows]\n",
    "            targets[j] = data[i + delay - 1, :]  # 预测所有特征，而不仅仅是价格\n",
    "            i += 1\n",
    "        yield samples, targets\n",
    "\n",
    "lookback = 50\n",
    "delay = 1\n",
    "batch_size = 32\n",
    "train_gen = generator(train_data, lookback=lookback, delay=delay, batch_size=batch_size)\n",
    "# test_gen = generator(test_data, lookback=lookback, delay=delay, batch_size=batch_size)\n",
    "\n",
    "model_path = 'stock_model.h5'  # 确保路径是正确的\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    # 加载模型\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    # 定义模型\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, input_shape=(lookback, data_scaled.shape[-1])))\n",
    "    model.add(Dense(data_scaled.shape[-1]))  # 输出层的单元数量现在匹配特征的数量\n",
    "    model.compile(optimizer=Adam(), loss='mse')\n",
    "\n",
    "    # model.fit(train_gen, epochs=20, steps_per_epoch=500, validation_data=test_gen, validation_steps=50)\n",
    "    model.fit(train_gen, epochs=60, steps_per_epoch=30)\n",
    "    # 保存模型\n",
    "    model.save(model_path)\n",
    "\n",
    "# 对未来500个价格数据进行预测\n",
    "future = 100\n",
    "data_to_predict = data_scaled[-lookback:]  # 最后lookback个数据点\n",
    "predicted_data = []\n",
    "for _ in range(future):\n",
    "    samples = np.reshape(data_to_predict[-lookback:], (1, lookback, data_scaled.shape[-1]))\n",
    "    predictions = model.predict(samples)\n",
    "    last_prediction = predictions[0, :]  # 获取所有预测特征\n",
    "    predicted_data.append(last_prediction)\n",
    "    data_to_predict = np.vstack([data_to_predict[1:], [last_prediction]])  # 使用所有预测特征\n",
    "\n",
    "# 对最后500个预测结果进行反归一化\n",
    "predicted_data = np.array(predicted_data)\n",
    "predicted_data = scaler.inverse_transform(predicted_data)\n",
    "predicted_data[:, 1] = np.maximum(predicted_data[:, 1], 0)\n",
    "\n",
    "\n",
    "# 保存预测结果到csv文件\n",
    "predicted_df = pd.DataFrame(predicted_data, columns=['predicted_price', 'predicted_vol'])\n",
    "predicted_df.to_csv('predicted_data_lstm.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
