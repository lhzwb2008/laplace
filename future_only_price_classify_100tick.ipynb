{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zhangwenbo/testProjects/laplace/future_only_price_classify_100tick.ipynb 单元格 1\u001b[0m line \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangwenbo/testProjects/laplace/future_only_price_classify_100tick.ipynb#W2sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m rf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhangwenbo/testProjects/laplace/future_only_price_classify_100tick.ipynb#W2sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m# rf = RandomForestRegressor(n_estimators=100, random_state=42)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zhangwenbo/testProjects/laplace/future_only_price_classify_100tick.ipynb#W2sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m rf\u001b[39m.\u001b[39;49mfit(X_train_month_clean, y_train_month_clean)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. 数据加载和预处理\n",
    "data = pd.read_csv(\"merged_sorted_file1.csv\")\n",
    "data_clean = data.dropna(subset=['current']).copy()\n",
    "# 1. 数据加载和预处理\n",
    "# data = pd.read_csv(\"SF主力连续.csv\",encoding=\"gb2312\")\n",
    "# data['time'] = pd.to_datetime(data['date'].astype(str) + ' ' + data['datetime'])\n",
    "# data = data.sort_values(by='time')\n",
    "# data_clean = data.dropna(subset=['current']).copy()\n",
    "\n",
    "\n",
    "# 2. 特征生成\n",
    "# Calculate rolling mean and standard deviation\n",
    "data_clean['rolling_mean'] = data_clean['current'].rolling(window=600).mean()\n",
    "data_clean['rolling_std'] = data_clean['current'].rolling(window=600).std()\n",
    "# data_clean = data_clean.fillna(data_clean.median())\n",
    "\n",
    "# Calculate RSI\n",
    "delta = data_clean['current'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "avg_gain = gain.rolling(window=800).mean()\n",
    "avg_loss = loss.rolling(window=800).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "data_clean['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# Calculate MACD\n",
    "short_ema = data_clean['current'].ewm(span=200, adjust=False).mean()\n",
    "long_ema = data_clean['current'].ewm(span=800, adjust=False).mean()\n",
    "data_clean['MACD'] = short_ema - long_ema\n",
    "data_clean['MACD_signal'] = data_clean['MACD'].ewm(span=800, adjust=False).mean()\n",
    "\n",
    "# Shift RSI and MACD to use them as features for next timestep\n",
    "data_clean['RSI_shifted'] = data_clean['RSI'].shift(1)\n",
    "data_clean['MACD_shifted'] = data_clean['MACD'].shift(1)\n",
    "data_clean['MACD_signal_shifted'] = data_clean['MACD_signal'].shift(1)\n",
    "\n",
    "# Define label\n",
    "data_clean['label'] = (data_clean['current'].shift(-100) > data_clean['current']).astype(int)\n",
    "\n",
    "\n",
    "# # 2. 特征生成\n",
    "# # Calculate rolling mean and standard deviation\n",
    "# data_clean['rolling_mean'] = data_clean['current'].rolling(window=5).mean()\n",
    "# data_clean['rolling_std'] = data_clean['current'].rolling(window=5).std()\n",
    "# data_clean = data_clean.fillna(data_clean.median())\n",
    "\n",
    "# # Calculate RSI\n",
    "# delta = data_clean['current'].diff()\n",
    "# gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "# loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "# avg_gain = gain.rolling(window=14).mean()\n",
    "# avg_loss = loss.rolling(window=14).mean()\n",
    "# rs = avg_gain / avg_loss\n",
    "# data_clean['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# # Calculate MACD\n",
    "# short_ema = data_clean['current'].ewm(span=12, adjust=False).mean()\n",
    "# long_ema = data_clean['current'].ewm(span=26, adjust=False).mean()\n",
    "# data_clean['MACD'] = short_ema - long_ema\n",
    "# data_clean['MACD_signal'] = data_clean['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# # Shift RSI and MACD to use them as features for next timestep\n",
    "# data_clean['RSI_shifted'] = data_clean['RSI'].shift(1)\n",
    "# data_clean['MACD_shifted'] = data_clean['MACD'].shift(1)\n",
    "# data_clean['MACD_signal_shifted'] = data_clean['MACD_signal'].shift(1)\n",
    "\n",
    "# # Define label\n",
    "# data_clean['label'] = (data_clean['current'].shift(-120) > data_clean['current']).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# 3. 分割数据\n",
    "data_clean['date_only'] = pd.to_datetime(data_clean['time']).dt.date\n",
    "# Updated the data split to use 'date_only'\n",
    "first_date = data_clean['date_only'].iloc[0]\n",
    "first_month_data = data_clean[data_clean['date_only'] <= first_date + pd.Timedelta(days=20)]\n",
    "# first_month_data = data_clean[(data_clean['date_only'] > first_date + pd.Timedelta(days=40)) & \n",
    "#                                (data_clean['date_only'] <= first_date + pd.Timedelta(days=70))]\n",
    "features = ['current', 'rolling_mean', 'rolling_std', 'RSI_shifted', 'MACD_shifted', 'MACD_signal_shifted']\n",
    "X_first_month = first_month_data[features]\n",
    "y_first_month = first_month_data['label']\n",
    "\n",
    "X_train_month_clean = X_first_month.dropna()\n",
    "y_train_month_clean = y_first_month[X_train_month_clean.index]\n",
    "\n",
    "\n",
    "# 4. 模型训练\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf.fit(X_train_month_clean, y_train_month_clean)  # Use the cleaned data for training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n",
      "Time: 2023-09-22 09:01:55 - Action: BUY at 7516.0, Quantity: 13.0,Funds:2290.0\n",
      "0.49\n",
      "Time: 2023-09-22 09:03:15 - Action: SELL at 7498.0, Quantity: 13.0,Funds:99764.0, Price Change: 跌\n",
      "0.91\n",
      "Time: 2023-09-22 09:13:20 - Action: BUY at 7468.0, Quantity: 13.0,Funds:2678.0\n",
      "0.49\n",
      "Time: 2023-09-22 09:18:10 - Action: SELL at 7474.0, Quantity: 13.0,Funds:99840.0, Price Change: 涨\n",
      "0.91\n",
      "Time: 2023-09-25 09:12:42 - Action: BUY at 7512.0, Quantity: 13.0,Funds:2182.0\n",
      "0.49\n",
      "Time: 2023-09-25 09:16:10 - Action: SELL at 7512.0, Quantity: 13.0,Funds:99838.0, Price Change: 平\n",
      "0.91\n",
      "Time: 2023-09-25 13:31:22 - Action: BUY at 7506.0, Quantity: 13.0,Funds:2258.0\n",
      "0.4\n",
      "Time: 2023-09-25 13:34:09 - Action: SELL at 7494.0, Quantity: 13.0,Funds:99680.0, Price Change: 跌\n",
      "0.91\n",
      "Time: 2023-09-25 14:22:12 - Action: BUY at 7486.0, Quantity: 13.0,Funds:2360.0\n",
      "0.49\n",
      "Time: 2023-09-25 14:24:36 - Action: SELL at 7488.0, Quantity: 13.0,Funds:99704.0, Price Change: 涨\n",
      "0.92\n",
      "Time: 2023-09-26 09:00:07 - Action: BUY at 7432.0, Quantity: 13.0,Funds:3086.0\n",
      "0.49\n",
      "Time: 2023-09-26 09:01:01 - Action: SELL at 7470.0, Quantity: 13.0,Funds:100196.0, Price Change: 涨\n",
      "0.92\n",
      "Time: 2023-09-26 09:33:11 - Action: BUY at 7498.0, Quantity: 13.0,Funds:2720.0\n",
      "0.41\n",
      "Time: 2023-09-26 09:34:11 - Action: SELL at 7492.0, Quantity: 13.0,Funds:100116.0, Price Change: 跌\n",
      "0.91\n",
      "Time: 2023-09-26 13:40:46 - Action: BUY at 7542.0, Quantity: 13.0,Funds:2068.0\n",
      "0.48\n",
      "Time: 2023-09-26 13:45:03 - Action: SELL at 7520.0, Quantity: 13.0,Funds:99828.0, Price Change: 跌\n",
      "0.92\n",
      "Time: 2023-09-27 09:58:50 - Action: BUY at 7526.0, Quantity: 13.0,Funds:1988.0\n",
      "0.47\n",
      "Time: 2023-09-27 10:03:46 - Action: SELL at 7542.0, Quantity: 13.0,Funds:100034.0, Price Change: 涨\n",
      "0.91\n",
      "Time: 2023-09-28 09:02:59 - Action: BUY at 7542.0, Quantity: 13.0,Funds:1986.0\n",
      "0.49\n",
      "Time: 2023-09-28 09:06:01 - Action: SELL at 7542.0, Quantity: 13.0,Funds:100032.0, Price Change: 平\n",
      "跌    4\n",
      "涨    4\n",
      "平    2\n",
      "Name: price_change, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#涨跌预测\n",
    "import collections\n",
    "# 5. 使用第二个月的数据进行预测\n",
    "second_month_data = data_clean[(data_clean['date_only'] > first_date + pd.Timedelta(days=20)) & \n",
    "                               (data_clean['date_only'] <= first_date + pd.Timedelta(days=30))]\n",
    "\n",
    "# 预测的初始化\n",
    "probabilities_second_month = []\n",
    "\n",
    "\n",
    "initial_funds = 100000\n",
    "funds = initial_funds\n",
    "stock_quantity = 0\n",
    "stock_price = 0\n",
    "buy_threshold = 0.9\n",
    "sold_threshold = 0.5\n",
    "transactions = []\n",
    "\n",
    "# 在逐行预测和模拟交易部分，初始化买入价格为0\n",
    "buy_price = 0\n",
    "minute_count = 0\n",
    "daily_transaction_count = 0  # 新增：每天的交易次数计数器\n",
    "\n",
    "for idx, row in second_month_data.iterrows():\n",
    "    current_row = row[features].fillna(method='ffill')\n",
    "    current_probability = rf.predict_proba([current_row])[0][1]\n",
    "        \n",
    "    current_price = row['current']\n",
    "    minute_count = minute_count + 1\n",
    "\n",
    "    flag = 1\n",
    "    # time_string = row['time'].strftime('%H:%M:%S')\n",
    "    time_string = row['time'][-8:]  # 获取时间部分，例如 \"22:59:10\"\n",
    "    if time_string.startswith(\"22:59:\"):\n",
    "        daily_transaction_count = 0\n",
    "        flag = 0\n",
    "        \n",
    "    if current_probability > buy_threshold and stock_quantity == 0 and daily_transaction_count<10 and flag==1:\n",
    "        print(current_probability)\n",
    "        daily_transaction_count += 1  # 新增：每次交易后增加计数器\n",
    "        stock_quantity = funds // current_price\n",
    "        funds -= stock_quantity * current_price\n",
    "        stock_price = current_price\n",
    "        fee = stock_quantity * current_price * 0.0001\n",
    "        funds -= fee\n",
    "        buy_price = current_price  # 记录买入价格\n",
    "        print(f\"Time: {row['time']} - Action: BUY at {current_price}, Quantity: {stock_quantity},Funds:{funds}\")\n",
    "        transactions.append({\n",
    "            'action': 'buy',\n",
    "            'time': row['time'],\n",
    "            'price': current_price,\n",
    "            'quantity': stock_quantity,\n",
    "            'funds_remaining': funds\n",
    "        })\n",
    "        minute_count = 0\n",
    "    # elif minute_count > 100 and stock_quantity > 0 or  (stock_quantity > 0 and flag==0) :\n",
    "    elif current_probability < sold_threshold and stock_quantity > 0 and minute_count>100 or (stock_quantity > 0 and flag==0):\n",
    "        print(current_probability)\n",
    "        funds += stock_quantity * current_price\n",
    "        fee = stock_quantity * current_price * 0.0001\n",
    "        funds -= fee\n",
    "        price_diff = current_price - buy_price  # 计算价格差异\n",
    "        # 判断价格差异是涨、跌还是平\n",
    "        if price_diff > 0:\n",
    "            direction = '涨'\n",
    "        elif price_diff < 0:\n",
    "            direction = '跌'\n",
    "        else:\n",
    "            direction = '平'\n",
    "        print(f\"Time: {row['time']} - Action: SELL at {current_price}, Quantity: {stock_quantity},Funds:{funds}, Price Change: {direction}\")\n",
    "        transactions.append({\n",
    "            'action': 'sell',\n",
    "            'time': row['time'],\n",
    "            'price': current_price,\n",
    "            'quantity': stock_quantity,\n",
    "            'funds_remaining': funds,\n",
    "            'price_change': direction\n",
    "        })\n",
    "        stock_quantity = 0\n",
    "        buy_price = 0  # 重置买入价格为0\n",
    "    \n",
    "    \n",
    "\n",
    "transactions_df = pd.DataFrame(transactions)\n",
    "print(transactions_df['price_change'].value_counts())\n",
    "transactions_df.to_csv('transactions_classify.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
